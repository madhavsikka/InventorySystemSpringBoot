---
version: "3"
services:
    zookeeper:
        image: confluentinc/cp-zookeeper:5.4.0
        container_name: zookeeper
        environment:
            TZ: Asia/India
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        # volumes:
        #   - ./data/container_data/zk-data:/var/lib/zookeeper/data
        #   - ./data/container_data/zk-txn-logs:/var/lib/zookeeper/log

    kafka-1:
        image: confluentinc/cp-enterprise-kafka:5.4.0
        container_name: kafka-1
        depends_on:
            - zookeeper
        ports:
            - 9092:9092
        environment:
            TZ: Asia/India
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:39092,HOST://0.0.0.0:9092
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:39092,HOST://localhost:9092
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        # volumes:
        #   - ./data/container_data/kafka-1-data:/var/lib/kafka/data

    schema-registry:
        image: confluentinc/cp-schema-registry:5.4.0
        ports:
            - 8081:8081
        container_name: schema-registry
        depends_on:
            - zookeeper
            - kafka-1
        environment:
            SCHEMA_REGISTRY_HOST_NAME: schema-registry
            SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka-1:39092
            SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT: 300

    kafka-connect-01:
        image: confluentinc/cp-kafka-connect:5.4.0
        container_name: kafka-connect-01
        depends_on:
            - kafka-1
            - schema-registry
        ports:
            - 8083:8083
        environment:
            CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
            CONNECT_CUB_KAFKA_TIMEOUT: 300
            CONNECT_BOOTSTRAP_SERVERS: "kafka-1:39092"
            CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect-01"
            CONNECT_REST_PORT: 8083
            CONNECT_GROUP_ID: kafka-connect-group-01
            CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-group-01-configs
            CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-group-01-offsets
            CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-group-01-status
            CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
            CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
            CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
            CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
            CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
            CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
            CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
            CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
            CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components/"
            # External secrets config
            # See https://docs.confluent.io/current/connect/security.html#externalizing-secrets
            CONNECT_CONFIG_PROVIDERS: "file"
            CONNECT_CONFIG_PROVIDERS_FILE_CLASS: "org.apache.kafka.common.config.provider.FileConfigProvider"
        command:
            # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
            - bash
            - -c
            - |
                echo "Installing connector plugins"
                confluent-hub install --no-prompt confluentinc/kafka-connect-influxdb:1.1.2
                #
                echo "Launching Kafka Connect worker"
                /etc/confluent/docker/run & 
                #
                echo "Waiting for Kafka Connect to start listening on $$CONNECT_REST_ADVERTISED_HOST_NAME:$$CONNECT_REST_PORT ⏳"
                while : ; do
                  curl_status=$$(curl -s -o /dev/null -w %{http_code} http://$$CONNECT_REST_ADVERTISED_HOST_NAME:$$CONNECT_REST_PORT/connectors)
                  echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
                  if [ $$curl_status -eq 200 ] ; then
                    break
                  fi
                  sleep 5 
                done
                #
                echo "Waiting for Schema Registry to start listening on schema-registry:8081 ⏳"
                while [ $$(curl -s -o /dev/null -w %{http_code} http://schema-registry:8081) -eq 000 ] ; do 
                  echo -e $$(date) " Schema Registry listener HTTP state: " $$(curl -s -o /dev/null -w %{http_code} http://schema-registry:8081) " (waiting for != 000)"
                  sleep 5 
                done
                #   
                echo -e "\n--\n+> Creating InfluxDB Connect Sink"
                curl -X PUT http://localhost:8083/connectors/sink_influx_json_01/config -H "Content-Type: application/json" -d '{
                    "connector.class"               : "io.confluent.influxdb.InfluxDBSinkConnector",
                    "value.converter"               : "org.apache.kafka.connect.json.JsonConverter",
                    "value.converter.schemas.enable": "true",
                    "key.converter"                 : "org.apache.kafka.connect.storage.StringConverter",
                    "topics"                        : "spark_stream",
                    "influxdb.url"                  : "http://influxdb:8086",
                    "influxdb.db"                   : "spark_db",
                    "measurement.name.format"       : "$${topic}"
                  }'
                #   
                sleep infinity

    kafka-connect-02:
        image: confluentinc/cp-kafka-connect:5.4.0
        container_name: kafka-connect-02
        depends_on:
            - kafka-1
            - schema-registry
        links:
            - mysql
        ports:
            - 28083:8083
        environment:
            CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
            CONNECT_CUB_KAFKA_TIMEOUT: 300
            CONNECT_BOOTSTRAP_SERVERS: "kafka-1:39092"
            CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect-02"
            CONNECT_REST_PORT: 8083
            CONNECT_GROUP_ID: kafka-connect-group-02
            CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-group-02-configs
            CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-group-02-offsets
            CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-group-02-status
            CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
            CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
            # CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverters
            CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
            CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
            # CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
            # CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
            CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
            CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
            CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
            CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
            CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components/"
            # External secrets config
            # See https://docs.confluent.io/current/connect/security.html#externalizing-secrets
            CONNECT_CONFIG_PROVIDERS: "file"
            CONNECT_CONFIG_PROVIDERS_FILE_CLASS: "org.apache.kafka.common.config.provider.FileConfigProvider"
        command:
            # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
            - bash
            - -c
            - |
                echo "Installing Debezium connector plugins"
                confluent-hub install --no-prompt debezium/debezium-connector-mysql:latest
                #
                echo "Launching Kafka Connect worker"
                /etc/confluent/docker/run & 
                #
                echo "Waiting for Kafka Connect to start listening on $$CONNECT_REST_ADVERTISED_HOST_NAME:$$CONNECT_REST_PORT ⏳"
                while : ; do
                  curl_status=$$(curl -s -o /dev/null -w %{http_code} http://$$CONNECT_REST_ADVERTISED_HOST_NAME:$$CONNECT_REST_PORT/connectors)
                  echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
                  if [ $$curl_status -eq 200 ] ; then
                    break
                  fi
                  sleep 5 
                done
                #
                echo "Waiting for Schema Registry to start listening on schema-registry:8081 ⏳"
                while [ $$(curl -s -o /dev/null -w %{http_code} http://schema-registry:8081) -eq 000 ] ; do 
                  echo -e $$(date) " Schema Registry listener HTTP state: " $$(curl -s -o /dev/null -w %{http_code} http://schema-registry:8081) " (waiting for != 000)"
                  sleep 5 
                done
                #   
                echo -e "\n--\n+> Creating Debezium Connector"
                curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{ 
                  "name": "inventory-connector", 
                  "config": 
                    { "connector.class": "io.debezium.connector.mysql.MySqlConnector", 
                    "tasks.max": "1", 
                    "database.hostname": "mysql", 
                    "database.port": "3306", 
                    "database.user": "debezium", 
                    "database.password": "dbz", 
                    "database.server.id": "184054", 
                    "database.server.name": "dbserver1", 
                    "database.include.list": "inventory", 
                    "database.history.kafka.bootstrap.servers": "kafka-1:39092",
                    "database.history.kafka.topic": "dbhistory.inventory" 
                    } 
                  }'
                #   
                sleep infinity

    mysql:
        image: debezium/example-mysql:latest
        container_name: mysql
        ports:
            - 3306:3306
        environment:
            - MYSQL_ROOT_PASSWORD=debezium
            - MYSQL_USER=mysqluser
            - MYSQL_PASSWORD=mysqlpw

    spring-jar:
        image: docker-spring-boot
        container_name: spring
        ports:
            - 7078:7078
        depends_on:
            - mysql

    influxdb:
        image: influxdb:1.7.9
        container_name: influxdb
        ports:
            - 8086:8086
        environment:
            - TZ=Asia/India

    grafana:
        image: grafana/grafana:latest
        container_name: grafana
        depends_on:
            - influxdb
        ports:
            - 3000:3000
        volumes:
            - grafana-storage:/var/lib/grafana

volumes:
    grafana-storage:
        external: true
